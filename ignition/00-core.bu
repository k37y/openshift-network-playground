variant: fcos
version: 1.0.0
passwd:
  groups:
    - name: libvirtd
  users:
    - name: core
      gecos: CoreOS Admin
      groups:
        - sudo
        - wheel
        - adm
        - systemd-journal
    - name: onp
      gecos: OpenShift Network Playground User
      groups:
        - sudo
        - wheel
        - adm
        - systemd-journal
        - libvirtd
      password_hash: $y$j9T$PNaoSZJskJ6WwR/2iS78a0$/6.dOJ1S2UWLMz0F/1mJvNN4dH3EZ1Y68hLfBsODgi0
systemd:
  units:
    - name: systemd-resolved.service
      enabled: false
      mask: true
    - name: zincati.service
      enabled: false
    - name: libvirtd.socket
      enabled: true
    - name: host-configure.service
      enabled: true
      contents: |
        [Unit]
        Wants=network-online.target
        After=network-online.target

        [Service]
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/host/configure.sh
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: master0.service
      enabled: true
      contents: |
        [Unit]
        Wants=libvirtd.socket
        After=libvirtd.socket
        Requires=libvirtd.socket
        ConditionPathExists=!/opt/openshift-network-playground/master0.done

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/libvirt/create-vm.sh master0 52:54:00:11:22:b1 52:54:00:11:22:a1
        ExecStartPost=/usr/bin/touch /opt/openshift-network-playground/master0.done
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: master1.service
      enabled: true
      contents: |
        [Unit]
        Wants=libvirtd.socket
        After=libvirtd.socket
        Requires=libvirtd.socket
        ConditionPathExists=!/opt/openshift-network-playground/master1.done

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/libvirt/create-vm.sh master1 52:54:00:11:22:b2 52:54:00:11:22:a2
        ExecStartPost=/usr/bin/touch /opt/openshift-network-playground/master1.done
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: master2.service
      enabled: true
      contents: |
        [Unit]
        Wants=libvirtd.socket
        After=libvirtd.socket
        Requires=libvirtd.socket
        ConditionPathExists=!/opt/openshift-network-playground/master2.done

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/libvirt/create-vm.sh master2 52:54:00:11:22:b3 52:54:00:11:22:a3
        ExecStartPost=/usr/bin/touch /opt/openshift-network-playground/master2.done
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: worker0.service
      enabled: true
      contents: |
        [Unit]
        Wants=libvirtd.socket
        After=libvirtd.socket
        Requires=libvirtd.socket
        ConditionPathExists=!/opt/openshift-network-playground/worker0.done

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/libvirt/create-vm.sh worker0 52:54:00:11:22:b4 52:54:00:11:22:a4 2 8192
        ExecStartPost=/usr/bin/touch /opt/openshift-network-playground/worker0.done
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: worker1.service
      enabled: true
      contents: |
        [Unit]
        Wants=libvirtd.socket
        After=libvirtd.socket
        Requires=libvirtd.socket
        ConditionPathExists=!/opt/openshift-network-playground/worker1.done

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/libvirt/create-vm.sh worker1 52:54:00:11:22:b5 52:54:00:11:22:a5 2 8192
        ExecStartPost=/usr/bin/touch /opt/openshift-network-playground/worker1.done
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
    - name: webserver.service
      enabled: true
      contents: |
        [Unit]
        Description=Webserver for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=on-failure
        TimeoutStopSec=70
        ExecStartPre=/bin/rm -f %t/%n.ctr-id
        ExecStart=/usr/bin/podman run \
                --cidfile=%t/%n.ctr-id \
                --cgroups=no-conmon \
                --rm \
                --sdnotify=conmon \
                --replace \
                --detach \
                --net host \
                --name webserver \
                -v /home/onp/openshift-network-playground/rhcos_image_cache:/var/www/html quay.io/centos7/httpd-24-centos7:latest
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: vbmc.service
      enabled: true
      contents: |
        [Unit]
        Description=vbmc for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=always
        TimeoutStopSec=70
        TimeoutStartSec=600
        ExecStartPre=/usr/bin/rm -f %t/%n.ctr-id
        ExecStartPre=/usr/bin/rm -vf /opt/openshift-network-playground/vbmc/config/master.pid
        ExecStart=/usr/bin/podman run \
                --cidfile=%t/%n.ctr-id \
                --cgroups=no-conmon \
                --rm \
                --sdnotify=conmon \
                --replace \
                -d \
                -ti \
                --name vbmc \
                --net host \
                --volume "/opt/openshift-network-playground/vbmc/config:/root/.vbmc" \
                --volume "/opt/openshift-network-playground/vbmc/ssh:/root/.ssh" \
                quay.io/metal3-io/vbmc
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: dhcp.service
      enabled: true
      contents: |
        [Unit]
        Description=DHCP for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=always
        TimeoutStartSec=180
        TimeoutStopSec=70
        ExecStartPre=-/usr/bin/rm -f %t/%n.ctr-id
        ExecStartPre=/usr/bin/podman build --net host --tag localhost/dhcp /opt/openshift-network-playground/dhcp
        ExecStart=/usr/bin/podman run --cidfile=%t/%n.ctr-id --cgroups=no-conmon --rm --sdnotify=conmon --name dhcp -d --net host --cap-add NET_ADMIN,NET_RAW localhost/dhcp
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: onp1-dhcp.service
      enabled: false
      contents: |
        [Unit]
        Description=DHCP for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=always
        TimeoutStartSec=180
        TimeoutStopSec=70
        ExecStartPre=-/usr/bin/rm -f %t/%n.ctr-id
        ExecStartPre=/usr/bin/podman build --net host --tag localhost/onp1-dhcp /opt/openshift-network-playground/onp1-dhcp
        ExecStart=/usr/bin/podman run --cidfile=%t/%n.ctr-id --cgroups=no-conmon --rm --sdnotify=conmon --name onp1-dhcp -d --net host --cap-add NET_ADMIN,NET_RAW localhost/onp1-dhcp
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: onp2-dhcp.service
      enabled: false
      contents: |
        [Unit]
        Description=DHCP for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=always
        TimeoutStartSec=180
        TimeoutStopSec=70
        ExecStartPre=-/usr/bin/rm -f %t/%n.ctr-id
        ExecStartPre=/usr/bin/podman build --net host --tag localhost/onp2-dhcp /opt/openshift-network-playground/onp2-dhcp
        ExecStart=/usr/bin/podman run --cidfile=%t/%n.ctr-id --cgroups=no-conmon --rm --sdnotify=conmon --name onp2-dhcp -d --net host --cap-add NET_ADMIN,NET_RAW localhost/onp2-dhcp
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: pxe.service
      enabled: false
      contents: |
        [Unit]
        Description=PXE for openshift-network-playground
        Wants=network-online.target
        After=network-online.target
        RequiresMountsFor=%t/containers

        [Service]
        Environment=PODMAN_SYSTEMD_UNIT=%n
        Restart=always
        TimeoutStartSec=180
        TimeoutStopSec=70
        ExecStartPre=-/usr/bin/rm -f %t/%n.ctr-id
        ExecStartPre=/usr/bin/podman build --net host --tag localhost/pxe /opt/openshift-network-playground/pxe
        ExecStart=/usr/bin/podman run --cidfile=%t/%n.ctr-id --cgroups=no-conmon --rm --sdnotify=conmon --name pxe -d --net host --cap-add NET_ADMIN,NET_RAW localhost/pxe
        ExecStop=/usr/bin/podman stop --ignore --cidfile=%t/%n.ctr-id
        ExecStopPost=/usr/bin/podman rm -f --ignore --cidfile=%t/%n.ctr-id
        Type=notify
        NotifyAccess=all

        [Install]
        WantedBy=default.target
    - name: broadcast.service
      enabled: true
      contents: |
        [Unit]
        Description=Check containers status
        After=selinux-configure.service

        [Service]
        Timeout=0
        Type=oneshot
        ExecStart=/opt/openshift-network-playground/host/broadcast.sh
        RemainAfterExit=yes

        [Install]
        WantedBy=basic.target
storage:
  directories:
    - path: /home/onp/openshift-network-playground
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
    - path: /home/onp/openshift-network-playground/rhcos_image_cache
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
  files:
    - path: /opt/openshift-network-playground/vbmc/ssh/config
      mode: 0644
      overwrite: true
      contents:
        inline: |
          StrictHostKeyChecking no
    - path: /opt/openshift-network-playground/vbmc/config/master0/config
      mode: 0644
      user:
        id: 1001
      group:
        id: 1001
      overwrite: true
      contents:
        inline: |
          [VirtualBMC]
          username = admin
          password = password
          address = 192.168.123.1
          port = 6230
          domain_name = master0
          libvirt_uri = qemu+ssh://onp@192.168.123.1/system
          active = True
    - path: /opt/openshift-network-playground/vbmc/config/master1/config
      mode: 0644
      user:
        id: 1001
      group:
        id: 1001
      overwrite: true
      contents:
        inline: |
          [VirtualBMC]
          username = admin
          password = password
          address = 192.168.123.1
          port = 6231
          domain_name = master1
          libvirt_uri = qemu+ssh://onp@192.168.123.1/system
          active = True
    - path: /opt/openshift-network-playground/vbmc/config/master2/config
      mode: 0644
      user:
        id: 1001
      group:
        id: 1001
      overwrite: true
      contents:
        inline: |
          [VirtualBMC]
          username = admin
          password = password
          address = 192.168.123.1
          port = 6232
          domain_name = master2
          libvirt_uri = qemu+ssh://onp@192.168.123.1/system
          active = True
    - path: /opt/openshift-network-playground/vbmc/config/worker0/config
      mode: 0644
      user:
        id: 1001
      group:
        id: 1001
      overwrite: true
      contents:
        inline: |
          [VirtualBMC]
          username = admin
          password = password
          address = 192.168.123.1
          port = 6233
          domain_name = worker0
          libvirt_uri = qemu+ssh://onp@192.168.123.1/system
          active = True
    - path: /opt/openshift-network-playground/vbmc/config/worker1/config
      mode: 0644
      user:
        id: 1001
      group:
        id: 1001
      overwrite: true
      contents:
        inline: |
          [VirtualBMC]
          username = admin
          password = password
          address = 192.168.123.1
          port = 6234
          domain_name = worker1
          libvirt_uri = qemu+ssh://onp@192.168.123.1/system
          active = True
    - path: /etc/resolv.conf
      mode: 0644
      overwrite: true
      contents:
        inline: ""
    - path: /etc/sudoers.d/onp
      mode: 0644
      overwrite: true
      contents:
        inline: |
          onp ALL=(ALL) NOPASSWD: ALL
    - path: /etc/polkit-1/localauthority/50-local.d/50-libvirt-remote-access.pkla
      mode: 0644
      overwrite: true
      contents:
        inline: |
          [Remote libvirt SSH access]
          Identity=unix-group:libvirtd
          Action=org.libvirt.unix.manage
          ResultAny=yes
          ResultInactive=yes
          ResultActive=yes
    - path: /etc/libvirt/libvirt.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          uri_default = "qemu:///system"
    - path: /etc/sysctl.d/99-sysctl.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          net.ipv4.ip_forward = 1
    - path: /etc/ssh/sshd_config.d/20-enable-passwords.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          PasswordAuthentication yes
    - path: /opt/openshift-network-playground/host/configure.sh
      mode: 0755
      contents:
        inline: |
          #!/bin/sh
          /usr/sbin/iptables -t nat -I POSTROUTING -s 192.168.123.0/24 ! -d 192.168.123.0/24 -j MASQUERADE
          /usr/sbin/iptables -t nat -I POSTROUTING -s 192.168.123.0/24 ! -d 192.168.124.0/24 -j MASQUERADE
          /usr/sbin/iptables -t nat -I POSTROUTING -s 192.168.123.0/24 ! -d 192.168.125.0/24 -j MASQUERADE
          /usr/sbin/iptables -t nat -I PREROUTING -p tcp -i $(/usr/sbin/ip r | grep default | awk '{print $5}') --dport 443 -j DNAT --to-destination 192.168.123.89:443
          /usr/sbin/iptables -t nat -I PREROUTING -p tcp -i $(/usr/sbin/ip r | grep default | awk '{print $5}') --dport 80 -j DNAT --to-destination 192.168.123.89:80
          /usr/sbin/iptables -t nat -I PREROUTING -p tcp -i $(/usr/sbin/ip r | grep default | awk '{print $5}') --dport 6443 -j DNAT --to-destination 192.168.123.88:6443
          /usr/bin/test -f /opt/openshift-network-playground/vbmc/ssh/id_rsa || (ssh-keygen -N '' -f /opt/openshift-network-playground/vbmc/ssh/id_rsa && mkdir -p /home/onp/.ssh && cp /opt/openshift-network-playground/vbmc/ssh/id_rsa.pub /home/onp/.ssh/authorized_keys && chown onp:onp -R /home/onp/.ssh)
          /usr/bin/test -f /opt/openshift-network-playground/cockpit-ws.done || (/usr/bin/test -d /usr/share/cockpit && podman container runlabel --name cockpit-ws RUN quay.io/cockpit/ws && podman container runlabel INSTALL quay.io/cockpit/ws && systemctl enable cockpit.service && touch /opt/openshift-network-playground/cockpit-ws.done)
          /usr/bin/chown -R onp:onp /home/onp/.local
    - path: /etc/NetworkManager/system-connections/ens3.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=ens3
          type=ethernet
          autoconnect=yes
          interface-name=ens3
          [ipv4]
          method=auto
          [ipv6]
          method=disabled
    - path: /etc/NetworkManager/system-connections/baremetal-dummy.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=baremetal-dummy
          type=dummy
          interface-name=baremetal-dummy
          autoconnect=yes
          master=baremetal
          slave-type=bridge
          [ipv4]
          method=link-local
          [ipv6]
          method=disabled
    - path: /etc/NetworkManager/system-connections/baremetal.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=baremetal
          type=bridge
          autoconnect=yes
          interface-name=baremetal
          [ipv4]
          method=manual
          addresses=192.168.123.1
          [ipv6]
          method=disabled
          [bridge]
          mac-address=52:54:00:11:22:a0
          interface-name=baremetal
    - path: /etc/NetworkManager/system-connections/baremetal-slave.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=baremetal-slave
          type=ethernet
          interface-name=baremetal-dummy
          master=baremetal
          autoconnect=yes
          slave-type=bridge
    - path: /etc/NetworkManager/system-connections/provision-dummy.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=provision-dummy
          type=dummy
          interface-name=provision-dummy
          autoconnect=yes
          master=provisioning
          slave-type=bridge
          [ipv4]
          method=link-local
          [ipv6]
          method=disabled
    - path: /etc/NetworkManager/system-connections/provisioning.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=provisioning
          type=bridge
          interface-name=provisioning
          autoconnect=yes
          [ipv4]
          method=manual
          addresses=172.22.0.254/24
          [ipv6]
          method=disabled
          [bridge]
          mac-address=52:54:00:11:22:b0
          interface-name=provisioning
    - path: /etc/NetworkManager/system-connections/provisioning-slave.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=provisioning-slave
          type=ethernet
          interface-name=provision-dummy
          master=provisioning
          autoconnect=yes
          slave-type=bridge
    - path: /etc/NetworkManager/system-connections/onp1-dummy.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp1-dummy
          type=dummy
          interface-name=onp1-dummy
          autoconnect=yes
          master=onp1
          slave-type=bridge
          [ipv4]
          method=link-local
          [ipv6]
          method=disabled
    - path: /etc/NetworkManager/system-connections/onp1.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp1
          type=bridge
          autoconnect=yes
          interface-name=onp1
          [ipv4]
          method=manual
          addresses=192.168.124.1
          [ipv6]
          method=disabled
          [bridge]
          mac-address=52:54:00:11:22:c0
          interface-name=onp1
    - path: /etc/NetworkManager/system-connections/ocp1-slave.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp1-slave
          type=ethernet
          interface-name=onp1-dummy
          master=onp1
          autoconnect=yes
          slave-type=bridge
    - path: /etc/NetworkManager/system-connections/onp2-dummy.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp2-dummy
          type=dummy
          interface-name=onp2-dummy
          autoconnect=yes
          master=onp2
          slave-type=bridge
          [ipv4]
          method=link-local
          [ipv6]
          method=disabled
    - path: /etc/NetworkManager/system-connections/onp2.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp2
          type=bridge
          autoconnect=yes
          interface-name=onp2
          [ipv4]
          method=manual
          addresses=192.168.125.1
          [ipv6]
          method=disabled
          [bridge]
          mac-address=52:54:00:11:22:d0
          interface-name=onp2
    - path: /etc/NetworkManager/system-connections/ocp2-slave.nmconnection
      mode: 0600
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [connection]
          id=onp2-slave
          type=ethernet
          interface-name=onp2-dummy
          master=onp2
          autoconnect=yes
          slave-type=bridge
    - path: /etc/NetworkManager/conf.d/openshift-network-playground.conf
      mode: 0644
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          [main]
          plugins=keyfile
          dns=dnsmasq
    - path: /etc/NetworkManager/dnsmasq.d/openshift-network-playground.conf
      mode: 0644
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          address=/.apps.ocp.example.local/192.168.123.89
          addn-hosts=/etc/hosts
    - path: /etc/hosts
      mode: 0644
      overwrite: true
      user:
        name: root
      contents:
        inline: |
          127.0.0.1 localhost localhost.localdomain openshift-network-playground.ocp.example.local
          192.168.123.88 api.ocp.example.local
          192.168.123.90 bootstrap.ocp.example.local
          192.168.123.91 master0.ocp.example.local
          192.168.123.92 master1.ocp.example.local
          192.168.123.93 master2.ocp.example.local
          192.168.123.94 worker0.ocp.example.local
          192.168.123.95 worker1.ocp.example.local
          192.168.123.1 openshift-network-playground.ocp.example.local lb.ocp.example.local mirror.ocp.example.local proxy.ocp.example.local
    - path: /etc/zincati/config.d/90-disable-auto-updates.toml
      contents:
        inline: |
          [updates]
          enabled = false
    - path: /opt/openshift-network-playground/libvirt/create-vm.sh
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          #!/bin/bash
          # Create node for openshift-network-playground
          
          set -euxo pipefail
          
          VM_NAME=$1
          MAC1=$2
          MAC2=$3
          VM_DIR=/opt/openshift-network-playground/libvirt
          VM_DISK=$VM_DIR/$VM_NAME/$VM_NAME.img
          VCPU=${4:-4}
          MEMORY=${5:-16384}
          NETWORK1=bridge=provisioning,mac=$MAC1
          NETWORK2=bridge=baremetal,mac=$MAC2
          
          if virsh list | grep $VM_NAME 2>&1>/dev/null; then virsh destroy $VM_NAME 2>/dev/null; virsh undefine $VM_NAME 2>/dev/null; fi
          if virsh list --all | grep $VM_NAME 2>&1>/dev/null; then virsh undefine $VM_NAME 2>/dev/null; fi
          if [ ! -f $VM_DISK ] ; then mkdir -p $VM_DIR/$VM_NAME; qemu-img create $VM_DISK 120G; fi
          
          virsh define <(virt-install --name $VM_NAME \
                  --os-variant fedora-coreos-stable \
                  --vcpus $VCPU \
                  --memory $MEMORY \
                  --disk $VM_DISK \
                  --network $NETWORK1 \
                  --network $NETWORK2 \
                  --pxe \
                  --boot network,hd \
                  --graphics spice,listen=0.0.0.0 \
                  --video virtio \
                  --channel spicevmc \
                  --console pty,target.type=virtio \
                  --serial pty \
                  --noautoconsole \
                  --print-xml 2)
          touch /opt/openshift-network-playground/$VM_NAME.done
    - path: /opt/openshift-network-playground/dhcp/Containerfile
      mode: 0644
      overwrite: true
      contents:
        inline: |
          FROM fedora
          MAINTAINER "Vinu K" <vkochuku@redhat.com>
          RUN yum install -y dnsmasq
          ADD dnsmasq.conf /dnsmasq.conf
          ENTRYPOINT ["dnsmasq"]
          CMD ["-C", "/dnsmasq.conf"]
    - path: /opt/openshift-network-playground/dhcp/dnsmasq.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          no-daemon
          interface=baremetal
          dhcp-range=192.168.123.2,192.168.123.254,255.255.255.0
          except-interface=lo
          bind-interfaces
          log-dhcp
          dhcp-authoritative
          log-async
          dhcp-host=52:54:00:11:22:a1,master0.ocp.example.local,192.168.123.91
          dhcp-host=52:54:00:11:22:a2,master1.ocp.example.local,192.168.123.92
          dhcp-host=52:54:00:11:22:a3,master2.ocp.example.local,192.168.123.93
          dhcp-host=52:54:00:11:22:a4,worker0.ocp.example.local,192.168.123.94
          dhcp-host=52:54:00:11:22:a5,worker1.ocp.example.local,192.168.123.95
    - path: /opt/openshift-network-playground/pxe/Containerfile
      mode: 0644
      overwrite: true
      contents:
        inline: |
          FROM fedora
          MAINTAINER "Vinu K" <vkochuku@redhat.com>
          RUN yum install -y dnsmasq
          ADD dnsmasq.conf /dnsmasq.conf
          ENTRYPOINT ["dnsmasq"]
          CMD ["-C", "/dnsmasq.conf"]
    - path: /opt/openshift-network-playground/pxe/dnsmasq.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          no-daemon
          interface=provisioning
          dhcp-range=172.22.0.3,172.22.0.253,255.255.255.0
          except-interface=lo
          bind-interfaces
          log-dhcp
          log-queries
          dhcp-authoritative
          log-async
          enable-tftp
          dhcp-userclass=set:ipxe,iPXE
          dhcp-boot=tag:ipxe,http://172.22.0.2/boot.ipxe
    - path: /opt/openshift-network-playground/onp1-dhcp/Containerfile
      mode: 0644
      overwrite: true
      contents:
        inline: |
          FROM fedora
          MAINTAINER "Vinu K" <vkochuku@redhat.com>
          RUN yum install -y dnsmasq
          ADD dnsmasq.conf /dnsmasq.conf
          ENTRYPOINT ["dnsmasq"]
          CMD ["-C", "/dnsmasq.conf"]
    - path: /opt/openshift-network-playground/onp1-dhcp/dnsmasq.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          no-daemon
          interface=onp1
          dhcp-range=192.168.124.2,192.168.124.254,255.255.255.0
          except-interface=lo
          bind-interfaces
          log-dhcp
          dhcp-authoritative
          log-async
    - path: /opt/openshift-network-playground/onp2-dhcp/Containerfile
      mode: 0644
      overwrite: true
      contents:
        inline: |
          FROM fedora
          MAINTAINER "Vinu K" <vkochuku@redhat.com>
          RUN yum install -y dnsmasq
          ADD dnsmasq.conf /dnsmasq.conf
          ENTRYPOINT ["dnsmasq"]
          CMD ["-C", "/dnsmasq.conf"]
    - path: /opt/openshift-network-playground/onp2-dhcp/dnsmasq.conf
      mode: 0644
      overwrite: true
      contents:
        inline: |
          no-daemon
          interface=onp2
          dhcp-range=192.168.125.2,192.168.125.254,255.255.255.0
          except-interface=lo
          bind-interfaces
          log-dhcp
          dhcp-authoritative
          log-async
    - path: /home/onp/.Makefile
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          RELEASE ?= stable-4.10
          LOGLEVEL ?= info
          SCRIPT_DIR = $(shell cd -- "$( dirname -- "${BASH_SOURCE[0]:-$0}"; )" &> /dev/null && pwd 2> /dev/null; )
          CONTAINERS = $(shell sudo podman ps --format {{.Names}} | sort | grep -oE 'dhcp|vbmc|webserver' | xargs)
          VMS = $(shell sudo virsh list --all --name | head -n -1 | wc -l)
          TFF = $(shell ls /tmp/openshift-install-bootstrap-*/terraform.platform.auto.tfvars.json 2>/dev/null | wc -l)
          
          check-env:
          ifndef OCM_TOKEN
                $(error OCM_TOKEN is undefined | Get it from https://cloud.redhat.com/openshift/token)
          endif

          check-containers:
          ifneq ($(CONTAINERS),dhcp vbmc webserver)
                $(error The containerized services (dhcp vbmc webserver) are not ready. Check with 'sudo podman ps' and wait for a while to retry)
          endif

          check-vms:
          ifneq ($(VMS),5)
                $(error The VMs are not ready. Please restart the services with 'sudo systemctl restart master0 master1 master2 worker0 worker1' and retry)
          endif

          check-terraform-file:
          ifneq ($(TFF),1)
                $(error The terraform.platform.auto.tfvars.json file is not present in /tmp)
          endif
          
          .PHONY: ssh-pullsecret
          
          ssh-pullsecret: check-env
                @echo "Generating SSH keys and pullsecret ..."
                @openshift-network-playground/ssh-pullsecret.sh $(OCM_TOKEN)

          .PHONY: install-config

          install-config: /home/onp/openshift-network-playground/pullsecret /home/onp/openshift-network-playground/id_ed25519.pub
                @openshift-network-playground/install-config.sh $(RELEASE)

          .PHONY: manifests

          manifests: $(SCRIPT_DIR)/openshift-network-playground/clusterconfigs/install-config.yaml
                @echo "Generating manifests ..."
                @/usr/local/bin/openshift-baremetal-install --log-level=${LOGLEVEL} --dir=$(SCRIPT_DIR)/openshift-network-playground/clusterconfigs create manifests

          .PHONY: ignition-configs

          ignition-configs:
                @echo "Generating ignition-configs ..."
                @/usr/local/bin/openshift-baremetal-install --log-level=${LOGLEVEL} --dir=$(SCRIPT_DIR)/openshift-network-playground/clusterconfigs create ignition-configs
          
          .PHONY: cluster
          
          cluster: check-containers check-vms
                @echo "Creating cluster ..."
                @/usr/local/bin/openshift-baremetal-install --log-level=${LOGLEVEL} --dir=$(SCRIPT_DIR)/openshift-network-playground/clusterconfigs create cluster
          
          .PHONY: clean
          
          clean:
                @echo "Removing old bootstrap resources ..."
                -@$(SCRIPT_DIR)/openshift-network-playground/clean-bootstrap.sh
                @echo "Removing installation directory ..."
                -@rm -rfv $(SCRIPT_DIR)/openshift-network-playground/clusterconfigs
                @echo "Powering off master nodes ..."
                -@for i in master0 master1 master2; do sudo virsh destroy $$i; done
                @echo "!!! IGNORE THE ERRORS !!!"
          
          .PHONY: destroy
          
          destroy:
                @echo "Destroying bootrap ..."
                -@openshift-baremetal-install destroy --log-level=${LOGLEVEL} --dir=/home/onp/openshift-network-playground/clusterconfigs bootstrap
                @echo "Destroying cluster ..."
                -@openshift-baremetal-install destroy --log-level=${LOGLEVEL} --dir=/home/onp/openshift-network-playground/clusterconfigs cluster
                @echo "Removing installation directory ..."
                -@rm -rfv $(SCRIPT_DIR)/openshift-network-playground/clusterconfigs
                @echo "Powering off master nodes ..."
                -@for i in master0 master1 master2; do sudo virsh destroy $$i; done
                @echo "!!! IGNORE THE ERRORS !!!"

          .PHONY: deploy

          deploy: clean ssh-pullsecret install-config manifests core-passwd-auth cluster

          .PHONY: core-passwd-auth

          core-passwd-auth:
                sed "s/version: 4.x.x/version: $(shell oc version --client -o json | jq -r .releaseClientVersion | cut -d'.' -f'1-2').0/g" /home/onp/openshift-network-playground/99_openshift-machineconfig_99-master-core-passwd-auth.bu > /tmp/master-core-passwd-auth.bu
                sed "s/version: 4.x.x/version: $(shell oc version --client -o json | jq -r .releaseClientVersion | cut -d'.' -f'1-2').0/g" /home/onp/openshift-network-playground/99_openshift-machineconfig_99-worker-core-passwd-auth.bu > /tmp/worker-core-passwd-auth.bu
                podman run -i --rm quay.io/coreos/butane:release --strict < /tmp/master-core-passwd-auth.bu > /home/onp/openshift-network-playground/clusterconfigs/openshift/99_openshift-machineconfig_99-master-core-passwd-auth.yaml
                podman run -i --rm quay.io/coreos/butane:release --strict < /tmp/worker-core-passwd-auth.bu > /home/onp/openshift-network-playground/clusterconfigs/openshift/99_openshift-machineconfig_99-worker-core-passwd-auth.yaml

          .PHONY: onp-files

          onp-files:
                @echo "Cloning onp-files ..."
                @git clone https://github.com/kevydotvinu/onp-files

          .PHONY: ironic-client

          ironic-client: check-terraform-file
                @echo "Creating clouds.yaml file ..."
                -@jq -jr '"clouds:","\n","  metal3:","\n","    auth_type: http_basic","\n","    username: ",.ironic_username,"\n","    password: ",.ironic_password,"\n","    baremetal_endpoint_override: ",.ironic_uri,"\n","    baremetal_introspection_endpoint_override: ",.inspector_uri,"\n"' /tmp/openshift-*/terraform.platform.auto.tfvars.json > /home/onp/openshift-network-playground/clouds.yaml
                @echo "Starting ironic-client container ..."
                -@sudo podman run -ti --rm --entrypoint /bin/bash --net host -v /home/onp/openshift-network-playground/clouds.yaml:/clouds.yaml -e OS_CLOUD=metal3 quay.io/metal3-io/ironic-client:latest

          .PHONY: help

          help:
                @echo "Usage: onp [SUBCOMMAND] [VARIABLE_NAME]=<variable>"
                @echo ""
                @echo "Subcommands:"
                @echo "  ssh-pullsecret OCM_TOKEN=<OCM_TOKEN>   Generate SSH keys and download pullsecret file."
                @echo "  install-config                         Generate install-config.yaml file."
                @echo "  cluster                                Create an OpenShift cluster."
                @echo "  destroy                                Destroy installed cluster."
                @echo "  clean                                  Clean old cluster resources."
                @echo "  ironic-client                          Create ironic-client container."
                @echo ""
                @echo "Example:"
                @echo "  onp cluster LOGLEVEL=debug"
                @echo ""
                @echo "Variables:"
                @echo "  OCM_TOKEN (token from https://cloud.redhat.com/openshift/token)"
                @echo "  RELEASE (stable-4.10, latest-4.9, 4.9.0, etc)"
                @echo "  LOGLEVEL (debug, info, warn, error)"
    - path: /home/onp/openshift-network-playground/clean-bootstrap.sh
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          #!/bin/bash
          #
          # Remove old bootstrap resources if any are left over from a previous deployment attempt
          
          set -xo pipefail
          
          BOOTSTRAP_RESOURCES=$(sudo virsh pool-list | grep bootstrap | awk '{print $1}' | xargs)
          
          if [ -z ${BOOTSTRAP_RESOURCES} ]; then
                  echo "No bootstrap resources ..."
          else
                  for RESOURCE in ${BOOTSTRAP_RESOURCES}; do
                          sudo virsh destroy ${RESOURCE}
                          sudo virsh undefine ${RESOURCE}
                          sudo virsh pool-start ${RESOURCE}
                          sudo virsh vol-delete ${RESOURCE} --pool ${RESOURCE}
                          sudo virsh vol-delete ${RESOURCE}-base --pool ${RESOURCE}
                          sudo virsh vol-delete ${RESOURCE}.ign --pool ${RESOURCE}
                          sudo virsh pool-destroy ${RESOURCE}
                          sudo virsh pool-delete ${RESOURCE}
                          sudo virsh pool-undefine ${RESOURCE}
                  done
          fi
    - path: /home/onp/openshift-network-playground/ssh-pullsecret.sh
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          #!/bin/bash
          # Download pull secret using OpenShift Cluster Manager API Token
          
          set -euo pipefail
          
          function USAGE {
                  echo "Usage: $0 '<OCM API Token>'"
                  echo "You need to authenticate using a Bearer token, which you can get from the link: https://cloud.redhat.com/openshift/token"
                  exit 1
          }
          
          function DOWNLOAD_PULLSECRET {
                  export BEARER=$(curl \
                          --silent \
                          --data-urlencode "grant_type=refresh_token" \
                          --data-urlencode "client_id=cloud-services" \
                          --data-urlencode "refresh_token=${OCM_API_TOKEN}" \
                          https://sso.redhat.com/auth/realms/redhat-external/protocol/openid-connect/token | \
                          jq -r .access_token)
                  curl -s -X POST https://api.openshift.com/api/accounts_mgmt/v1/access_token --header "Content-Type:application/json" --header "Authorization: Bearer $BEARER" > ${SCRIPT_DIR}/pullsecret
          }
          
          function SSH_KEY {
                  rm -fv ${SCRIPT_DIR}/id_ed25519 ${SCRIPT_DIR}/id_ed25519.pub
                  ssh-keygen -q -t ed25519 -N '' -f ${SCRIPT_DIR}/id_ed25519
          }
          
          SCRIPT_DIR="$( cd -- "$( dirname -- "${BASH_SOURCE[0]:-$0}"; )" &> /dev/null && pwd 2> /dev/null; )"
          ARG_COUNT=${#}
          OCM_API_TOKEN=${1}
          ARG_SIZE=${#OCM_API_TOKEN}
          
          if [ ${ARG_COUNT} -eq 1 ] && [ ${ARG_SIZE} -gt 50 ]; then
                  ( SSH_KEY && echo "✔ SSH key generated!" ) || echo "✗ Error: SSH key generation failed!"
                  ( DOWNLOAD_PULLSECRET 1>/dev/null && echo "✔ Pull secret downloaded!" ) || echo "✗ Error: Pull secret download failed!"
          else
                  USAGE
          fi
    - path: /home/onp/openshift-network-playground/install-config.sh
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          set -euo pipefail

          SCRIPT_DIR="$( cd -- "$( dirname -- "${BASH_SOURCE[0]:-$0}"; )" &> /dev/null && pwd 2> /dev/null; )"
          export VERSION=${1}
          export RELEASE_IMAGE=$(curl -s https://mirror.openshift.com/pub/openshift-v4/clients/ocp/$VERSION/release.txt | grep 'Pull From: quay.io' | awk -F ' ' '{print $3}')
          export cmd=openshift-baremetal-install
          export pullsecret_file=${SCRIPT_DIR}/pullsecret
          export extract_dir=${SCRIPT_DIR}
          echo "Downloading oc binary ..."
          curl -s https://mirror.openshift.com/pub/openshift-v4/clients/ocp/$VERSION/openshift-client-linux.tar.gz | tar zxf - -C ${SCRIPT_DIR} oc
          sudo mv ${SCRIPT_DIR}/oc /usr/local/bin
          echo "✔ Downloaded!"
          echo "Downloading openshift-install binary ..."
          /usr/local/bin/oc adm release extract --registry-config "${pullsecret_file}" --command=$cmd --to "${extract_dir}" ${RELEASE_IMAGE}
          sudo mv ${SCRIPT_DIR}/openshift-baremetal-install /usr/local/bin
          echo "✔ Downloaded!"
          export RHCOS_QEMU_URI=$(/usr/local/bin/openshift-baremetal-install coreos print-stream-json | jq -r --arg ARCH "$(arch)" '.architectures[$ARCH].artifacts.qemu.formats["qcow2.gz"].disk.location')
          export RHCOS_QEMU_NAME=${RHCOS_QEMU_URI##*/}
          export RHCOS_QEMU_UNCOMPRESSED_SHA256=$(/usr/local/bin/openshift-baremetal-install coreos print-stream-json | jq -r --arg ARCH "$(arch)" '.architectures[$ARCH].artifacts.qemu.formats["qcow2.gz"].disk["uncompressed-sha256"]')
          echo "Downloading bootstrap os image ..."
          [ -f "/home/onp/openshift-network-playground/rhcos_image_cache/${RHCOS_QEMU_NAME}" ] || curl -sL ${RHCOS_QEMU_URI} -o /home/onp/openshift-network-playground/rhcos_image_cache/${RHCOS_QEMU_NAME}
          echo "✔ Downloaded!"
          export BAREMETAL_IP=$(ip addr show dev baremetal | awk '/inet /{print $2}' | cut -d"/" -f1)
          export BOOTSTRAP_OS_IMAGE="http://${BAREMETAL_IP}:8080/${RHCOS_QEMU_NAME}?sha256=${RHCOS_QEMU_UNCOMPRESSED_SHA256}"
          echo "Generating install-config.yaml file ..."
          cat << EOF > ${SCRIPT_DIR}/install-config.yaml
          apiVersion: v1
          baseDomain: example.local
          metadata:
            name: ocp
          networking:
            machineNetwork:
            - cidr: 192.168.123.0/24
            networkType: OVNKubernetes
          compute:
          - name: worker
            replicas: 0
          controlPlane:
            name: master
            replicas: 3
            platform:
              baremetal: {}
          platform:
            baremetal:
              libvirtURI: qemu:///system
              bootstrapOSImage: ${BOOTSTRAP_OS_IMAGE}
              apiVIP: 192.168.123.88
              ingressVIP: 192.168.123.89
              provisioningNetworkCIDR: 172.22.0.0/24
              hosts:
                - name: master0
                  role: master
                  bmc:
                    address: ipmi://192.168.123.1:6230
                    username: admin
                    password: password
                  bootMACAddress: 52:54:00:11:22:b1
                  hardwareProfile: libvirt
                  rootDeviceHints:
                   deviceName: "/dev/vda"
                - name: master1
                  role: master
                  bmc:
                    address: ipmi://192.168.123.1:6231
                    username: admin
                    password: password
                  bootMACAddress: 52:54:00:11:22:b2
                  hardwareProfile: libvirt
                  rootDeviceHints:
                   deviceName: "/dev/vda"
                - name: master2
                  role: master
                  bmc:
                    address: ipmi://192.168.123.1:6232
                    username: admin
                    password: password
                  bootMACAddress: 52:54:00:11:22:b3
                  hardwareProfile: libvirt
                  rootDeviceHints:
                   deviceName: "/dev/vda"
          pullSecret: '$(cat ${SCRIPT_DIR}/pullsecret)'
          sshKey: '$(cat ${SCRIPT_DIR}/id_ed25519.pub)'
          EOF
          echo "✔ Generated!"
          mkdir -p ${SCRIPT_DIR}/clusterconfigs
          echo "Copying install-config.yaml file to clusterconfigs directory ..."
          cp ${SCRIPT_DIR}/install-config.yaml ${SCRIPT_DIR}/clusterconfigs/
          echo "✔ Copied!"
    - path: /opt/openshift-network-playground/host/broadcast.sh
      mode: 0755
      overwrite: true
      contents:
        inline: |
          #!/bin/sh
          while true; do if [[ $(podman ps --format json | jq -r '.[] | .Names | .[]' | wc -l) == "3" ]]; then echo -e "The containerized services ($(podman ps --format json | jq -r '.[] | .Names | .[]' | xargs)) are ready.\nYou can start the OpenShift baremetal IPI installation now." | wall -n; break; fi; done
    - path: /home/onp/.bashrc
      append:
        - inline: |
            alias onp='make -C /home/onp -f /home/onp/.Makefile'
            export EDITOR=vi
            export KUBECONFIG=/home/onp/openshift-network-playground/clusterconfigs/auth/kubeconfig
            sed -i -e 's/      /\t/g' /home/onp/.Makefile
    - path: /home/onp/openshift-network-playground/worker0.yaml
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          apiVersion: v1
          kind: Secret
          metadata:
            name: openshift-worker-0-bmc-secret
            namespace: openshift-machine-api
          type: Opaque
          data:
            username: YWRtaW4K
            password: cGFzc3dvcmQK
          ---
          apiVersion: metal3.io/v1alpha1
          kind: BareMetalHost
          metadata:
            name: openshift-worker-0
            namespace: openshift-machine-api
          spec:
            online: true
            bootMACAddress: 52:54:00:11:22:b4
            bmc:
              address: ipmi://192.168.123.1:6233
              credentialsName: openshift-worker-0-bmc-secret
            rootDeviceHints:
              deviceName: "/dev/vda"
    - path: /home/onp/openshift-network-playground/worker1.yaml
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          apiVersion: v1
          kind: Secret
          metadata:
            name: openshift-worker-1-bmc-secret
            namespace: openshift-machine-api
          type: Opaque
          data:
            username: YWRtaW4K
            password: cGFzc3dvcmQK
          ---
          apiVersion: metal3.io/v1alpha1
          kind: BareMetalHost
          metadata:
            name: openshift-worker-1
            namespace: openshift-machine-api
          spec:
            online: true
            bootMACAddress: 52:54:00:11:22:b5
            bmc:
              address: ipmi://192.168.123.1:6234
              credentialsName: openshift-worker-1-bmc-secret
            rootDeviceHints:
              deviceName: "/dev/vda"
    - path: /home/onp/openshift-network-playground/99_openshift-machineconfig_99-master-core-passwd-auth.bu
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          variant: openshift
          version: 4.x.x
          metadata:
            labels:
              machineconfiguration.openshift.io/role: master
            name: 99-master-onp
          storage:
            files:
            - path: /etc/ssh/sshd_config.d/99-onp.conf
              mode: 0644
              overwrite: true
              contents:
                inline: |
                  PasswordAuthentication yes
          systemd:
            units:
            - name: onp.service
              enabled: true
              contents: |
                [Service]
                Type=oneshot
                ExecStart=/usr/bin/sh -c '/usr/bin/echo "Core@123" | /usr/bin/passwd --stdin core'
                RemainAfterExit=yes
                [Install]
                WantedBy=multi-user.target
    - path: /home/onp/openshift-network-playground/99_openshift-machineconfig_99-worker-core-passwd-auth.bu
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          variant: openshift
          version: 4.x.x
          metadata:
            labels:
              machineconfiguration.openshift.io/role: worker
            name: 99-worker-onp
          storage:
            files:
            - path: /etc/ssh/sshd_config.d/99-onp.conf
              mode: 0644
              overwrite: true
              contents:
                inline: |
                  PasswordAuthentication yes
          systemd:
            units:
            - name: onp.service
              enabled: true
              contents: |
                [Service]
                Type=oneshot
                ExecStart=/usr/bin/sh -c '/usr/bin/echo "Core@123" | /usr/bin/passwd --stdin core'
                RemainAfterExit=yes
                [Install]
                WantedBy=multi-user.target
    - path: /home/onp/.local/share/cockpit/openshift/deploy-cluster.sh
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          #!/bin/bash
          # This script initiates an OpenShift cluster deployment in transient systemd service.
          sudo systemd-run --uid=onp --unit=deploy-cluster --description='OpenShift cluster deployment' make -C /home/onp/ -f /home/onp/.Makefile deploy RELEASE=${1} OCM_TOKEN=${2}
          journalctl -f -u deploy-cluster.service
    - path: /home/onp/.local/share/cockpit/openshift/manifest.json
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          {
            "version": 0,
            "tools": {
              "openshift": {
                "label": "OpenShift",
                "path": "openshift.html"
              }
            }
          }
    - path: /home/onp/.local/share/cockpit/openshift/openshift.html
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          <!DOCTYPE html>
          <html>
          <head>
              <title>OpenShift</title>
              <meta charset="utf-8">
              <script src="../base1/cockpit.js"></script>
          </head>
          <body class="pf-m-redhat-font">
              <main tabindex="-1">
                  <section>
                      <div id="app">
                          <div>
                              <label for="release">Release</label>
                              <input id="release" value="4.12.2">
                          </div>
                          <div>
                              <label for="token">OCM Token</label>
                              <input id="token" value="token">
                          </div>
                          <div>
                              <button id="deploy">Deploy</button>
                              <span id="result"></span>
                          </div>
                          <div>
                              <pre id="output"></pre>
                          </div>
                      </div>
                  </section>
              </main>

              <script src="openshift.js"></script>
          </body>
          </html>
    - path: /home/onp/.local/share/cockpit/openshift/openshift.js
      mode: 0755
      overwrite: true
      user:
        name: onp
      group:
        name: onp
      contents:
        inline: |
          const release = document.getElementById("release");
          const token = document.getElementById("token");
          const output = document.getElementById("output");
          const result = document.getElementById("result");
          const button = document.getElementById("deploy");

          function deploy_run() {
              /* global cockpit */
              cockpit.spawn(["/home/onp/.local/share/cockpit/openshift/deploy-cluster.sh", release.value, token.value])
                      .stream(deploy_output)
                      .then(deploy_success)
                      .catch(deploy_fail);

              result.innerHTML = "";
              output.innerHTML = "";
          }

          function deploy_success() {
              result.style.color = "green";
              result.innerHTML = "success";
          }

          function deploy_fail() {
              result.style.color = "red";
              result.innerHTML = "fail";
          }

          function deploy_output(data) {
              output.append(document.createTextNode(data));
          }

          // Connect the button to starting the "deploy" process
          button.addEventListener("click", deploy_run);

          // Send a 'init' message.  This tells integration tests that we are ready to go
          cockpit.transport.wait(function() { });
